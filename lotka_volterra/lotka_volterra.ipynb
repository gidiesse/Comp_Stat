{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Lotka Volterra problem"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow.compat.v1\n",
      "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/giuliadesanctis/PycharmProjects/compStat/venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# We import the necessary libraries\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "from deepxde.backend import tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Since this is a trivial problem, we know the values of R and U a priori but here we will use them to solve\n",
    "# the problem so that we can then check how well our NN performs when estimating them.\n",
    "rb = 20 # real value of R\n",
    "ub = 200 # real value of U\n",
    "\n",
    "# Function to simulate system\n",
    "def func(t, r):\n",
    "    x, y = r\n",
    "    dx_t = 1 / ub * rb * (2.0 * ub * x - 0.04 * ub * x * ub * y)\n",
    "    dy_t = 1 / ub * rb * (0.02 * ub * x * ub * y - 1.06 * ub * y)\n",
    "    return dx_t, dy_t\n",
    "\n",
    "# Function that generates the true solution of the problem\n",
    "def gen_truedata():\n",
    "    t = np.linspace(0., 1., 25)\n",
    "\n",
    "    sol = integrate.solve_ivp(func, (0, 1), (100 / ub, 15 / ub), t_eval=t)\n",
    "    x_true, y_true = sol.y\n",
    "    x_true = x_true.reshape(25, 1)\n",
    "    y_true = y_true.reshape(25, 1)\n",
    "\n",
    "    return t, np.hstack([x_true, y_true])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From now on, we \"forget\" the values of R and U and we will \"find\" them using our Neural Network. At the end\n",
    "we will check how well it has performed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our aim is to find the 2 unknown variables (R and U) for the system of equations.\n",
    "#R = dde.Variable(15.) # R\n",
    "U = dde.Variable(215.) # U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Express the ODE system, x represents the coordinate t, y is a 2D vector that contains r(t) and p(t)\n",
    "def LV_system(x, y):\n",
    "    r = y[:, 0:1]\n",
    "    p = y[:, 1:2]\n",
    "    dr_t = dde.grad.jacobian(y, x, i=0)\n",
    "    dp_t = dde.grad.jacobian(y, x, i=1)\n",
    "    #return [\n",
    "    #    dr_t - 1 / U * R * (2.0 * U * r - 0.04 * U * r * U * p),\n",
    "    #    dp_t - 1 / U * R * (0.02 * r * U * p * U - 1.06 * p * U),\n",
    "    #]\n",
    "    return [\n",
    "            dr_t - 1 / U * 20 * (2.0 * U * r - 0.04 * U * r * U * p),\n",
    "            dp_t - 1 / U * 20 * (0.02 * r * U * p * U - 1.06 * p * U),\n",
    "        ]\n",
    "# x represents the t coordinate\n",
    "# y represents the network output ie the solution y(r(t),p(t))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# We need to implement a function that returns true for points inside the subdomain and false for the points outside\n",
    "def boundary(_, on_initial):\n",
    "    return on_initial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Define a time domain\n",
    "geom = dde.geometry.TimeDomain(0.0, 1.0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# We specify the initial conditions\n",
    "#ic1 = dde.icbc.IC(geom, lambda X: 100/C2, boundary, component=0)\n",
    "#ic2 = dde.icbc.IC(geom, lambda X: 15/C2, boundary, component=1)\n",
    "ic1 = dde.icbc.IC(geom, lambda X: 100/ub, boundary, component=0)\n",
    "ic2 = dde.icbc.IC(geom, lambda X: 15/ub, boundary, component=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Organize and assign training data\n",
    "observe_t, ob_y = gen_truedata()\n",
    "observe_t = observe_t.reshape(25, 1)\n",
    "observe_y0 = dde.icbc.PointSetBC(observe_t, ob_y[:, 0:1], component=0)\n",
    "observe_y1 = dde.icbc.PointSetBC(observe_t, ob_y[:, 1:2], component=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Define the ODE problem\n",
    "data = dde.data.PDE(\n",
    "    geom,\n",
    "    LV_system,\n",
    "    [ic1, ic2, observe_y0, observe_y1],\n",
    "    num_domain=3000,\n",
    "    num_boundary=2,\n",
    "    anchors=observe_t) # extra points used for training, added reading lorenz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Create the net\n",
    "layer_size = [1] + [64] * 6 + [2]\n",
    "activation = \"tanh\"\n",
    "initializer = \"Glorot normal\"\n",
    "net = dde.nn.FNN(layer_size, activation, initializer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# We add a feature layer with sin(kt) since we expect Lotka-Volterra to be periodic. The sin(kt) forces the prediction\n",
    "# to be periodic and thus more accurate\n",
    "def input_transform(t):\n",
    "    return tf.concat(\n",
    "        (\n",
    "            t,\n",
    "            tf.sin(t),\n",
    "            tf.sin(2 * t),\n",
    "            tf.sin(3 * t),\n",
    "            tf.sin(4 * t),\n",
    "            tf.sin(5 * t),\n",
    "            tf.sin(6 * t),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def output_transform(t, y):\n",
    "    y1 = y[:, 0:1]\n",
    "    y2 = y[:, 1:2]\n",
    "\n",
    "    return tf.concat(\n",
    "        [y1 * tf.tanh(t) + 100 / ub, y2 * tf.tanh(t) + 15 / ub], axis=1\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# We give indications that C1 and C2 need to be trained alongside the other parameters in the NN. This\n",
    "# is how we estimate their value. They will then be saved in a file called variables.dat\n",
    "external_trainable_variables = [U]\n",
    "#external_trainable_variables = [R, U]\n",
    "variable = dde.callbacks.VariableValue(\n",
    "    external_trainable_variables, period=600, filename=\"variables.dat\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# We add the layer to impose periodicity we've just created\n",
    "net.apply_feature_transform(input_transform)\n",
    "net.apply_output_transform(output_transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Warning: For the backend tensorflow.compat.v1, `external_trainable_variables` is ignored, and all trainable ``tf.Variable`` objects are automatically collected.\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.030904 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giuliadesanctis/PycharmProjects/compStat/venv/lib/python3.11/site-packages/deepxde/nn/tensorflow_compat_v1/fnn.py:116: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'compile' took 0.339932 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                                                      Test loss                                                       Test metric\n",
      "0         [6.34e+02, 4.35e+00, 0.00e+00, 0.00e+00, 1.46e-01, 1.47e-01]    [6.34e+02, 4.35e+00, 0.00e+00, 0.00e+00, 1.46e-01, 1.47e-01]    []  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 20:18:20.653260: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000      [2.74e+00, 7.17e-01, 0.00e+00, 0.00e+00, 9.82e-02, 3.93e-02]    [2.74e+00, 7.17e-01, 0.00e+00, 0.00e+00, 9.82e-02, 3.93e-02]    []  \n",
      "2000      [1.61e+00, 6.65e-01, 0.00e+00, 0.00e+00, 9.17e-02, 3.46e-02]    [1.61e+00, 6.65e-01, 0.00e+00, 0.00e+00, 9.17e-02, 3.46e-02]    []  \n",
      "3000      [1.46e+01, 7.57e-01, 0.00e+00, 0.00e+00, 1.03e-01, 4.39e-02]    [1.46e+01, 7.57e-01, 0.00e+00, 0.00e+00, 1.03e-01, 4.39e-02]    []  \n",
      "4000      [5.71e+00, 8.78e-01, 0.00e+00, 0.00e+00, 9.82e-02, 3.87e-02]    [5.71e+00, 8.78e-01, 0.00e+00, 0.00e+00, 9.82e-02, 3.87e-02]    []  \n",
      "5000      [3.38e+00, 9.03e-01, 0.00e+00, 0.00e+00, 9.58e-02, 3.77e-02]    [3.38e+00, 9.03e-01, 0.00e+00, 0.00e+00, 9.58e-02, 3.77e-02]    []  \n",
      "6000      [2.54e+00, 7.90e-01, 0.00e+00, 0.00e+00, 9.24e-02, 3.60e-02]    [2.54e+00, 7.90e-01, 0.00e+00, 0.00e+00, 9.24e-02, 3.60e-02]    []  \n",
      "7000      [2.05e+00, 7.14e-01, 0.00e+00, 0.00e+00, 8.77e-02, 3.26e-02]    [2.05e+00, 7.14e-01, 0.00e+00, 0.00e+00, 8.77e-02, 3.26e-02]    []  \n",
      "8000      [1.71e+00, 6.66e-01, 0.00e+00, 0.00e+00, 8.18e-02, 2.78e-02]    [1.71e+00, 6.66e-01, 0.00e+00, 0.00e+00, 8.18e-02, 2.78e-02]    []  \n",
      "9000      [1.39e+00, 6.34e-01, 0.00e+00, 0.00e+00, 7.40e-02, 2.35e-02]    [1.39e+00, 6.34e-01, 0.00e+00, 0.00e+00, 7.40e-02, 2.35e-02]    []  \n",
      "10000     [8.95e-01, 5.10e-01, 0.00e+00, 0.00e+00, 7.09e-02, 2.56e-02]    [8.95e-01, 5.10e-01, 0.00e+00, 0.00e+00, 7.09e-02, 2.56e-02]    []  \n",
      "11000     [1.04e+00, 3.89e-01, 0.00e+00, 0.00e+00, 7.40e-02, 2.74e-02]    [1.04e+00, 3.89e-01, 0.00e+00, 0.00e+00, 7.40e-02, 2.74e-02]    []  \n",
      "12000     [4.97e-01, 3.73e-01, 0.00e+00, 0.00e+00, 6.97e-02, 2.58e-02]    [4.97e-01, 3.73e-01, 0.00e+00, 0.00e+00, 6.97e-02, 2.58e-02]    []  \n",
      "13000     [3.26e-01, 2.55e-01, 0.00e+00, 0.00e+00, 7.25e-02, 2.66e-02]    [3.26e-01, 2.55e-01, 0.00e+00, 0.00e+00, 7.25e-02, 2.66e-02]    []  \n",
      "14000     [4.59e-01, 3.25e-01, 0.00e+00, 0.00e+00, 6.76e-02, 2.12e-02]    [4.59e-01, 3.25e-01, 0.00e+00, 0.00e+00, 6.76e-02, 2.12e-02]    []  \n",
      "15000     [4.52e-01, 2.23e-01, 0.00e+00, 0.00e+00, 7.02e-02, 2.58e-02]    [4.52e-01, 2.23e-01, 0.00e+00, 0.00e+00, 7.02e-02, 2.58e-02]    []  \n",
      "16000     [1.16e-01, 1.41e-01, 0.00e+00, 0.00e+00, 6.98e-02, 2.59e-02]    [1.16e-01, 1.41e-01, 0.00e+00, 0.00e+00, 6.98e-02, 2.59e-02]    []  \n",
      "17000     [7.14e-02, 1.05e-01, 0.00e+00, 0.00e+00, 6.36e-02, 2.31e-02]    [7.14e-02, 1.05e-01, 0.00e+00, 0.00e+00, 6.36e-02, 2.31e-02]    []  \n",
      "18000     [4.51e-02, 7.66e-02, 0.00e+00, 0.00e+00, 5.85e-02, 2.07e-02]    [4.51e-02, 7.66e-02, 0.00e+00, 0.00e+00, 5.85e-02, 2.07e-02]    []  \n",
      "19000     [6.92e-02, 6.87e-02, 0.00e+00, 0.00e+00, 5.71e-02, 2.00e-02]    [6.92e-02, 6.87e-02, 0.00e+00, 0.00e+00, 5.71e-02, 2.00e-02]    []  \n",
      "20000     [6.70e-02, 5.12e-02, 0.00e+00, 0.00e+00, 5.51e-02, 1.92e-02]    [6.70e-02, 5.12e-02, 0.00e+00, 0.00e+00, 5.51e-02, 1.92e-02]    []  \n",
      "21000     [1.39e-02, 3.92e-02, 0.00e+00, 0.00e+00, 4.66e-02, 1.60e-02]    [1.39e-02, 3.92e-02, 0.00e+00, 0.00e+00, 4.66e-02, 1.60e-02]    []  \n",
      "22000     [7.37e-03, 3.27e-02, 0.00e+00, 0.00e+00, 3.35e-02, 1.15e-02]    [7.37e-03, 3.27e-02, 0.00e+00, 0.00e+00, 3.35e-02, 1.15e-02]    []  \n",
      "23000     [4.82e-03, 2.15e-02, 0.00e+00, 0.00e+00, 2.03e-02, 6.75e-03]    [4.82e-03, 2.15e-02, 0.00e+00, 0.00e+00, 2.03e-02, 6.75e-03]    []  \n",
      "24000     [1.86e-02, 1.29e-02, 0.00e+00, 0.00e+00, 1.32e-02, 3.93e-03]    [1.86e-02, 1.29e-02, 0.00e+00, 0.00e+00, 1.32e-02, 3.93e-03]    []  \n",
      "25000     [1.73e-02, 1.84e-02, 0.00e+00, 0.00e+00, 8.54e-03, 2.50e-03]    [1.73e-02, 1.84e-02, 0.00e+00, 0.00e+00, 8.54e-03, 2.50e-03]    []  \n",
      "26000     [1.82e-02, 5.40e-03, 0.00e+00, 0.00e+00, 5.49e-03, 1.74e-03]    [1.82e-02, 5.40e-03, 0.00e+00, 0.00e+00, 5.49e-03, 1.74e-03]    []  \n",
      "27000     [1.50e-03, 3.59e-03, 0.00e+00, 0.00e+00, 4.13e-03, 1.36e-03]    [1.50e-03, 3.59e-03, 0.00e+00, 0.00e+00, 4.13e-03, 1.36e-03]    []  \n",
      "28000     [8.51e-04, 2.78e-03, 0.00e+00, 0.00e+00, 3.10e-03, 1.17e-03]    [8.51e-04, 2.78e-03, 0.00e+00, 0.00e+00, 3.10e-03, 1.17e-03]    []  \n",
      "29000     [7.17e-04, 1.62e-03, 0.00e+00, 0.00e+00, 2.72e-03, 1.06e-03]    [7.17e-04, 1.62e-03, 0.00e+00, 0.00e+00, 2.72e-03, 1.06e-03]    []  \n",
      "30000     [6.35e-04, 1.31e-03, 0.00e+00, 0.00e+00, 2.54e-03, 1.01e-03]    [6.35e-04, 1.31e-03, 0.00e+00, 0.00e+00, 2.54e-03, 1.01e-03]    []  \n",
      "31000     [7.99e-04, 1.22e-03, 0.00e+00, 0.00e+00, 2.39e-03, 9.71e-04]    [7.99e-04, 1.22e-03, 0.00e+00, 0.00e+00, 2.39e-03, 9.71e-04]    []  \n",
      "32000     [5.25e-04, 8.62e-04, 0.00e+00, 0.00e+00, 2.17e-03, 9.08e-04]    [5.25e-04, 8.62e-04, 0.00e+00, 0.00e+00, 2.17e-03, 9.08e-04]    []  \n",
      "33000     [3.87e-04, 7.32e-04, 0.00e+00, 0.00e+00, 1.94e-03, 8.33e-04]    [3.87e-04, 7.32e-04, 0.00e+00, 0.00e+00, 1.94e-03, 8.33e-04]    []  \n",
      "34000     [3.95e-03, 1.69e-03, 0.00e+00, 0.00e+00, 2.01e-03, 8.18e-04]    [3.95e-03, 1.69e-03, 0.00e+00, 0.00e+00, 2.01e-03, 8.18e-04]    []  \n",
      "35000     [8.23e-04, 1.12e-03, 0.00e+00, 0.00e+00, 2.06e-03, 8.64e-04]    [8.23e-04, 1.12e-03, 0.00e+00, 0.00e+00, 2.06e-03, 8.64e-04]    []  \n",
      "36000     [3.82e-04, 5.37e-04, 0.00e+00, 0.00e+00, 1.83e-03, 8.05e-04]    [3.82e-04, 5.37e-04, 0.00e+00, 0.00e+00, 1.83e-03, 8.05e-04]    []  \n",
      "37000     [1.91e-01, 8.19e-02, 0.00e+00, 0.00e+00, 1.80e-03, 1.11e-03]    [1.91e-01, 8.19e-02, 0.00e+00, 0.00e+00, 1.80e-03, 1.11e-03]    []  \n",
      "38000     [3.63e-04, 4.68e-04, 0.00e+00, 0.00e+00, 1.77e-03, 7.87e-04]    [3.63e-04, 4.68e-04, 0.00e+00, 0.00e+00, 1.77e-03, 7.87e-04]    []  \n",
      "39000     [2.97e-02, 8.60e-03, 0.00e+00, 0.00e+00, 1.78e-03, 6.72e-04]    [2.97e-02, 8.60e-03, 0.00e+00, 0.00e+00, 1.78e-03, 6.72e-04]    []  \n",
      "40000     [2.10e-03, 7.59e-04, 0.00e+00, 0.00e+00, 1.64e-03, 7.66e-04]    [2.10e-03, 7.59e-04, 0.00e+00, 0.00e+00, 1.64e-03, 7.66e-04]    []  \n",
      "41000     [5.92e-04, 4.67e-04, 0.00e+00, 0.00e+00, 1.72e-03, 7.76e-04]    [5.92e-04, 4.67e-04, 0.00e+00, 0.00e+00, 1.72e-03, 7.76e-04]    []  \n",
      "42000     [6.16e-04, 6.05e-04, 0.00e+00, 0.00e+00, 1.66e-03, 7.34e-04]    [6.16e-04, 6.05e-04, 0.00e+00, 0.00e+00, 1.66e-03, 7.34e-04]    []  \n",
      "43000     [4.85e-04, 4.59e-04, 0.00e+00, 0.00e+00, 1.72e-03, 7.78e-04]    [4.85e-04, 4.59e-04, 0.00e+00, 0.00e+00, 1.72e-03, 7.78e-04]    []  \n",
      "44000     [9.86e-04, 6.47e-04, 0.00e+00, 0.00e+00, 1.67e-03, 7.60e-04]    [9.86e-04, 6.47e-04, 0.00e+00, 0.00e+00, 1.67e-03, 7.60e-04]    []  \n",
      "45000     [4.91e-04, 4.47e-04, 0.00e+00, 0.00e+00, 1.63e-03, 7.35e-04]    [4.91e-04, 4.47e-04, 0.00e+00, 0.00e+00, 1.63e-03, 7.35e-04]    []  \n",
      "46000     [1.50e-03, 7.55e-04, 0.00e+00, 0.00e+00, 1.56e-03, 7.13e-04]    [1.50e-03, 7.55e-04, 0.00e+00, 0.00e+00, 1.56e-03, 7.13e-04]    []  \n",
      "47000     [6.77e-02, 5.03e-02, 0.00e+00, 0.00e+00, 1.40e-03, 7.32e-04]    [6.77e-02, 5.03e-02, 0.00e+00, 0.00e+00, 1.40e-03, 7.32e-04]    []  \n",
      "48000     [3.30e-04, 2.87e-04, 0.00e+00, 0.00e+00, 1.54e-03, 7.08e-04]    [3.30e-04, 2.87e-04, 0.00e+00, 0.00e+00, 1.54e-03, 7.08e-04]    []  \n",
      "49000     [2.96e-04, 2.93e-04, 0.00e+00, 0.00e+00, 1.50e-03, 6.93e-04]    [2.96e-04, 2.93e-04, 0.00e+00, 0.00e+00, 1.50e-03, 6.93e-04]    []  \n",
      "50000     [9.06e-04, 3.16e-04, 0.00e+00, 0.00e+00, 1.61e-03, 7.27e-04]    [9.06e-04, 3.16e-04, 0.00e+00, 0.00e+00, 1.61e-03, 7.27e-04]    []  \n",
      "51000     [4.32e-03, 2.56e-03, 0.00e+00, 0.00e+00, 1.56e-03, 6.92e-04]    [4.32e-03, 2.56e-03, 0.00e+00, 0.00e+00, 1.56e-03, 6.92e-04]    []  \n",
      "52000     [1.52e-03, 6.59e-04, 0.00e+00, 0.00e+00, 1.49e-03, 6.74e-04]    [1.52e-03, 6.59e-04, 0.00e+00, 0.00e+00, 1.49e-03, 6.74e-04]    []  \n",
      "53000     [7.26e-03, 1.70e-03, 0.00e+00, 0.00e+00, 1.43e-03, 6.25e-04]    [7.26e-03, 1.70e-03, 0.00e+00, 0.00e+00, 1.43e-03, 6.25e-04]    []  \n",
      "54000     [5.14e-02, 2.17e-02, 0.00e+00, 0.00e+00, 1.40e-03, 8.21e-04]    [5.14e-02, 2.17e-02, 0.00e+00, 0.00e+00, 1.40e-03, 8.21e-04]    []  \n",
      "55000     [6.20e-04, 3.87e-04, 0.00e+00, 0.00e+00, 1.47e-03, 6.69e-04]    [6.20e-04, 3.87e-04, 0.00e+00, 0.00e+00, 1.47e-03, 6.69e-04]    []  \n",
      "56000     [1.57e-03, 7.83e-04, 0.00e+00, 0.00e+00, 1.49e-03, 6.74e-04]    [1.57e-03, 7.83e-04, 0.00e+00, 0.00e+00, 1.49e-03, 6.74e-04]    []  \n",
      "57000     [1.28e-03, 8.63e-04, 0.00e+00, 0.00e+00, 1.41e-03, 6.71e-04]    [1.28e-03, 8.63e-04, 0.00e+00, 0.00e+00, 1.41e-03, 6.71e-04]    []  \n",
      "58000     [2.73e-02, 4.35e-03, 0.00e+00, 0.00e+00, 1.51e-03, 8.05e-04]    [2.73e-02, 4.35e-03, 0.00e+00, 0.00e+00, 1.51e-03, 8.05e-04]    []  \n",
      "59000     [8.89e-04, 5.13e-04, 0.00e+00, 0.00e+00, 1.51e-03, 6.83e-04]    [8.89e-04, 5.13e-04, 0.00e+00, 0.00e+00, 1.51e-03, 6.83e-04]    []  \n",
      "60000     [3.93e-04, 2.40e-04, 0.00e+00, 0.00e+00, 1.44e-03, 6.83e-04]    [3.93e-04, 2.40e-04, 0.00e+00, 0.00e+00, 1.44e-03, 6.83e-04]    []  \n",
      "\n",
      "Best model at step 60000:\n",
      "  train loss: 2.76e-03\n",
      "  test loss: 2.76e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 703.897048 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now that the NN has been defined, we build a model, set the optimizer and learning rate and train it for 50,000 iterations\n",
    "#model = dde.Model(data, net)\n",
    "#model.compile(\"adam\", lr=0.001)\n",
    "#losshistory, train_state = model.train(iterations=50000)\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\n",
    "    \"adam\", lr=0.001, external_trainable_variables=external_trainable_variables\n",
    ")\n",
    "losshistory, train_state = model.train(iterations=60000, callbacks=[variable])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.139420 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                                                      Test loss                                                       Test metric\n",
      "60000     [3.93e-04, 2.40e-04, 0.00e+00, 0.00e+00, 1.44e-03, 6.83e-04]    [3.93e-04, 2.40e-04, 0.00e+00, 0.00e+00, 1.44e-03, 6.83e-04]    []  \n",
      "61000     [1.94e-04, 1.53e-04, 0.00e+00, 0.00e+00, 1.22e-03, 5.92e-04]    [1.94e-04, 1.53e-04, 0.00e+00, 0.00e+00, 1.22e-03, 5.92e-04]        \n",
      "62000     [1.93e-04, 1.55e-04, 0.00e+00, 0.00e+00, 1.17e-03, 5.67e-04]    [1.93e-04, 1.55e-04, 0.00e+00, 0.00e+00, 1.17e-03, 5.67e-04]        \n",
      "63000     [1.76e-04, 1.49e-04, 0.00e+00, 0.00e+00, 1.05e-03, 5.09e-04]    [1.76e-04, 1.49e-04, 0.00e+00, 0.00e+00, 1.05e-03, 5.09e-04]        \n",
      "64000     [1.79e-04, 1.38e-04, 0.00e+00, 0.00e+00, 8.56e-04, 4.22e-04]    [1.79e-04, 1.38e-04, 0.00e+00, 0.00e+00, 8.56e-04, 4.22e-04]        \n",
      "65000     [1.45e-04, 1.21e-04, 0.00e+00, 0.00e+00, 6.80e-04, 3.36e-04]    [1.45e-04, 1.21e-04, 0.00e+00, 0.00e+00, 6.80e-04, 3.36e-04]        \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# To further minimize the loss, we continue with L-BFGS\u001B[39;00m\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL-BFGS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m losshistory, train_state \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m dde\u001B[38;5;241m.\u001B[39msaveplot(losshistory, train_state, issave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, isplot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/deepxde/utils/internal.py:22\u001B[0m, in \u001B[0;36mtiming.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     21\u001B[0m     ts \u001B[38;5;241m=\u001B[39m timeit\u001B[38;5;241m.\u001B[39mdefault_timer()\n\u001B[0;32m---> 22\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m     te \u001B[38;5;241m=\u001B[39m timeit\u001B[38;5;241m.\u001B[39mdefault_timer()\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mrank \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/deepxde/model.py:640\u001B[0m, in \u001B[0;36mModel.train\u001B[0;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optimizers\u001B[38;5;241m.\u001B[39mis_external_optimizer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt_name):\n\u001B[1;32m    639\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m backend_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow.compat.v1\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 640\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_tensorflow_compat_v1_scipy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdisplay_every\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    641\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m backend_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    642\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_tensorflow_tfp()\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/deepxde/model.py:726\u001B[0m, in \u001B[0;36mModel._train_tensorflow_compat_v1_scipy\u001B[0;34m(self, display_every)\u001B[0m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexternal_trainable_variables:\n\u001B[1;32m    725\u001B[0m     fetches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexternal_trainable_variables\n\u001B[0;32m--> 726\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    727\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    729\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfetches\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    730\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss_callback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    731\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    732\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_test()\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/deepxde/optimizers/tensorflow_compat_v1/scipy_optimizer.py:181\u001B[0m, in \u001B[0;36mExternalOptimizerInterface.minimize\u001B[0;34m(self, session, feed_dict, fetches, step_callback, loss_callback, **run_kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m initial_packed_var_val \u001B[38;5;241m=\u001B[39m session\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_var)\n\u001B[1;32m    180\u001B[0m \u001B[38;5;66;03m# Perform minimization.\u001B[39;00m\n\u001B[0;32m--> 181\u001B[0m packed_var_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_minimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_packed_var_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss_grad_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_grad_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mequality_funcs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mequality_funcs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mequality_grad_funcs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mequality_grad_funcs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[43minequality_funcs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minequality_funcs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43minequality_grad_funcs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minequality_grad_funcs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpacked_bounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_packed_bounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstep_callback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    192\u001B[0m var_vals \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    193\u001B[0m     packed_var_val[packing_slice] \u001B[38;5;28;01mfor\u001B[39;00m packing_slice \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packing_slices\n\u001B[1;32m    194\u001B[0m ]\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# Set optimization variables to their new values.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/deepxde/optimizers/tensorflow_compat_v1/scipy_optimizer.py:382\u001B[0m, in \u001B[0;36mScipyOptimizerInterface._minimize\u001B[0;34m(self, initial_val, loss_grad_func, equality_funcs, equality_grad_funcs, inequality_funcs, inequality_grad_funcs, packed_bounds, step_callback, optimizer_kwargs)\u001B[0m\n\u001B[1;32m    378\u001B[0m minimize_kwargs\u001B[38;5;241m.\u001B[39mupdate(optimizer_kwargs)\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimize\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top\u001B[39;00m\n\u001B[0;32m--> 382\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mscipy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mminimize_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mminimize_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m message_lines \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    385\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimization terminated with:\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    386\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  Message: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    387\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  Objective function value: \u001B[39m\u001B[38;5;132;01m%f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    388\u001B[0m ]\n\u001B[1;32m    389\u001B[0m message_args \u001B[38;5;241m=\u001B[39m [result\u001B[38;5;241m.\u001B[39mmessage, result\u001B[38;5;241m.\u001B[39mfun]\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/scipy/optimize/_minimize.py:713\u001B[0m, in \u001B[0;36mminimize\u001B[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[1;32m    710\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[1;32m    711\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[1;32m    712\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 713\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_minimize_lbfgsb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    714\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    716\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[1;32m    717\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:369\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[1;32m    363\u001B[0m task_str \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[1;32m    366\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[1;32m    367\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[1;32m    368\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[0;32m--> 369\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW_X\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    371\u001B[0m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[1;32m    372\u001B[0m     n_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:296\u001B[0m, in \u001B[0;36mScalarFunction.fun_and_grad\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray_equal(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx):\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_x_impl(x)\n\u001B[0;32m--> 296\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_grad()\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:262\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[0;32m--> 262\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:163\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.update_fun\u001B[0;34m()\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_fun\u001B[39m():\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mfun_wrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:145\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnfev \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[0;32m--> 145\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:78\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[0;34m(self, x, *args)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m     77\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" returns the function value \"\"\"\u001B[39;00m\n\u001B[0;32m---> 78\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:72\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[0;34m(self, x, *args)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m---> 72\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/deepxde/optimizers/tensorflow_compat_v1/scipy_optimizer.py:344\u001B[0m, in \u001B[0;36mScipyOptimizerInterface._minimize.<locals>.loss_grad_func_wrapper\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mloss_grad_func_wrapper\u001B[39m(x):\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;66;03m# SciPy's L-BFGS-B Fortran implementation requires gradients as doubles.\u001B[39;00m\n\u001B[0;32m--> 344\u001B[0m     loss, gradient \u001B[38;5;241m=\u001B[39m \u001B[43mloss_grad_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss, gradient\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat64\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/deepxde/optimizers/tensorflow_compat_v1/scipy_optimizer.py:268\u001B[0m, in \u001B[0;36mExternalOptimizerInterface._make_eval_func.<locals>.eval_func\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    265\u001B[0m augmented_feed_dict\u001B[38;5;241m.\u001B[39mupdate(feed_dict)\n\u001B[1;32m    266\u001B[0m augmented_fetches \u001B[38;5;241m=\u001B[39m tensors \u001B[38;5;241m+\u001B[39m fetches\n\u001B[0;32m--> 268\u001B[0m augmented_fetch_vals \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43maugmented_fetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maugmented_feed_dict\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(callback):\n\u001B[1;32m    273\u001B[0m     callback(\u001B[38;5;241m*\u001B[39maugmented_fetch_vals[num_tensors:])\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/tensorflow/python/client/session.py:972\u001B[0m, in \u001B[0;36mBaseSession.run\u001B[0;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m    969\u001B[0m run_metadata_ptr \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_NewBuffer() \u001B[38;5;28;01mif\u001B[39;00m run_metadata \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    971\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 972\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions_ptr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mrun_metadata_ptr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    974\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m run_metadata:\n\u001B[1;32m    975\u001B[0m     proto_data \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/tensorflow/python/client/session.py:1215\u001B[0m, in \u001B[0;36mBaseSession._run\u001B[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1212\u001B[0m \u001B[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001B[39;00m\n\u001B[1;32m   1213\u001B[0m \u001B[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001B[39;00m\n\u001B[1;32m   1214\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m final_fetches \u001B[38;5;129;01mor\u001B[39;00m final_targets \u001B[38;5;129;01mor\u001B[39;00m (handle \u001B[38;5;129;01mand\u001B[39;00m feed_dict_tensor):\n\u001B[0;32m-> 1215\u001B[0m   results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_targets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_fetches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1216\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mfeed_dict_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1217\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1218\u001B[0m   results \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/tensorflow/python/client/session.py:1395\u001B[0m, in \u001B[0;36mBaseSession._do_run\u001B[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1392\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001B[1;32m   1394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1395\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_run_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeeds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1396\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1397\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1398\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/tensorflow/python/client/session.py:1402\u001B[0m, in \u001B[0;36mBaseSession._do_call\u001B[0;34m(self, fn, *args)\u001B[0m\n\u001B[1;32m   1400\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_do_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1401\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1402\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1403\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOpError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1404\u001B[0m     message \u001B[38;5;241m=\u001B[39m compat\u001B[38;5;241m.\u001B[39mas_text(e\u001B[38;5;241m.\u001B[39mmessage)\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/tensorflow/python/client/session.py:1385\u001B[0m, in \u001B[0;36mBaseSession._do_run.<locals>._run_fn\u001B[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[1;32m   1382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_fn\u001B[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001B[1;32m   1383\u001B[0m   \u001B[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001B[39;00m\n\u001B[1;32m   1384\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extend_graph()\n\u001B[0;32m-> 1385\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_tf_sessionrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetch_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1386\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mtarget_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compStat/venv/lib/python3.11/site-packages/tensorflow/python/client/session.py:1478\u001B[0m, in \u001B[0;36mBaseSession._call_tf_sessionrun\u001B[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[1;32m   1476\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_tf_sessionrun\u001B[39m(\u001B[38;5;28mself\u001B[39m, options, feed_dict, fetch_list, target_list,\n\u001B[1;32m   1477\u001B[0m                         run_metadata):\n\u001B[0;32m-> 1478\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_SessionRun_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1479\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mfetch_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# To further minimize the loss, we continue with L-BFGS\n",
    "model.compile(\"L-BFGS\")\n",
    "losshistory, train_state = model.train()\n",
    "dde.saveplot(losshistory, train_state, issave=True, isplot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"population\")\n",
    "\n",
    "t, y_true = gen_truedata()\n",
    "plt.plot(t, y_true[:, 0], color=\"black\", label=\"x_true\")\n",
    "plt.plot(t, y_true[:, 1], color=\"blue\", label=\"y_true\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = t.reshape(100, 1)\n",
    "sol_pred = model.predict(t)\n",
    "x_pred = sol_pred[:, 0:1]\n",
    "y_pred = sol_pred[:, 1:2]\n",
    "\n",
    "plt.plot(t, x_pred, color=\"red\", linestyle=\"dashed\", label=\"x_pred\")\n",
    "plt.plot(t, y_pred, color=\"orange\", linestyle=\"dashed\", label=\"y_pred\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = '/Users/giuliadesanctis/PycharmProjects/compStat/lotka_volterra/variables.dat'\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "C1 = []\n",
    "C2 = []\n",
    "C3 = []\n",
    "for line in lines:\n",
    "    line = line.split(\" \")\n",
    "    C1.append(float(line[1].replace(\",\", \"\").replace(\"[\",\"\").replace(\"]\",\"\")))\n",
    "C1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(C1)\n",
    "xx = np.linspace(0,60000,101)\n",
    "\n",
    "plt.xlabel(\"Num. iterations\")\n",
    "plt.ylabel(\"Prediction of U\")\n",
    "plt.title (\"Prediction of U - R frozen - initialized at 215\")\n",
    "plt.scatter(xx,C1)\n",
    "plt. axhline(y=200, color='r', linestyle='--', linewidth=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
